{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manifest File - Malware document embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to create document embeddings of the files which are present in the directories `appData/manifest`.  This folder contains benign and malicious files extracted from android APKs collected from AndroZoo, separated into folders `test` and `train`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the packages and declaring the datatype for loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utkarsh/.local/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import os\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "\n",
    "import multiprocessing\n",
    "from collections import OrderedDict\n",
    "\n",
    "import gensim.models.doc2vec\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `ManifestDocument` is declared `words` `tags` `split` `label` and `file_name` parameters are to be populated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ManifestDocument = collections.namedtuple('ManifestDocument', 'words tags split label file_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dir(directory, file_extension=\".txt\"):\n",
    "    cmd_out = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(file_extension):\n",
    "                cmd_out.append(os.path.join(root, file))\n",
    "    return cmd_out\n",
    "\n",
    "\n",
    "# Takes label, text, index, split, file_name as the input and returns a DexDocument\n",
    "def dex_doc(label, text, index, split, file_name):\n",
    "    tokens = gensim.parsing.preprocessing.strip_non_alphanum(text).split()\n",
    "    return ManifestDocument(tokens, [index], split, label, file_name)\n",
    "\n",
    "\n",
    "\n",
    "def extract_text(directory, file_extension=\".txt\"):\n",
    "    \"\"\"\n",
    "    This function takes directory as input param and lists all the files with file_extension=<str>.\n",
    "    It then reads each of file in the directory, based on file paths putting\n",
    "    malicious-non-maliciou flag and train-test flag for the document before yiedling a `dex_doc`\n",
    "    \"\"\"\n",
    "    file_names = list_dir(directory, file_extension)\n",
    "    index = 0\n",
    "    for dex_file in file_names:\n",
    "        if len(dex_file) > 0:\n",
    "            with open(dex_file, encoding=\"ISO-8859-1\") as f:\n",
    "#                 content = f.read(32000)\n",
    "                content = \"\"\n",
    "                file_name = extract_name_from_filepath(dex_file)\n",
    "                if \"malicious\" in dex_file:\n",
    "                    label = 1\n",
    "                else:\n",
    "                    label = 0\n",
    "\n",
    "                if \"train/\" in dex_file:\n",
    "                    split = \"train\"\n",
    "                elif \"test/\" in dex_file:\n",
    "                    split = \"test\"\n",
    "                \n",
    "                yield dex_doc(label, content, index, split, file_name)\n",
    "                index += 1\n",
    "        else:\n",
    "            print(\"Probably the end of list!\")\n",
    "\n",
    "\n",
    "def extract_name_from_filepath(file_name):\n",
    "    last_piece_of_string = file_name.split(\"\\\\\")[-1]\n",
    "    extracted_name = last_piece_of_string.replace(\"malicious_\", \"\").replace(\"benign_\",\"\")\\\n",
    "    .replace(\".apk_manifest.xml\", \".apk\").replace(\".dex.txt\", \"\")\n",
    "    return extracted_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing all the manifest files in directory and reading them into the `all_manifest_files` list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a77715b70323>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_manifest_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"manifest/train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "all_manifest_files = list(extract_text(\"manifest/train\", \".xml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating `train` and `test` docs based on the split parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs_manifests = [doc for doc in all_manifest_files if doc.split == 'train']\n",
    "print('%d docs: %d train-document' % (len(all_manifest_files), len(train_docs_manifests)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up training parameters and all model types - Manifest Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_kwargs = dict(\n",
    "#     vector_size=35, epochs=20, min_count=2,\n",
    "#     sample=0, workers=multiprocessing.cpu_count(), negative=10, hs=0,\n",
    "# )\n",
    "\n",
    "# simple_models_manifests = [\n",
    "#     # PV-DBOW plain\n",
    "#     Doc2Vec(dm=0, **common_kwargs),\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\#1. Building the vocabulary from the manifest files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"Building the Vocab with manifest files..\")\n",
    "\n",
    "# for model in simple_models_manifests:\n",
    "#     model.build_vocab(all_manifest_files)\n",
    "#     print(\"%s vocabulary scanned & state initialized\" % model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\#2. Training the document embeddings of manifest files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for model in simple_models_manifests:\n",
    "#     print(\"Training %s\" % model)\n",
    "#     model.train(all_manifest_files, total_examples=len(all_manifest_files), epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = simple_models_manifests[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec.load(\"./doc2vecmodel.mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_labels_and_features(test_model, train_set):\n",
    "    train_labels = []\n",
    "    train_features = []\n",
    "    \n",
    "    for doc in train_set:\n",
    "        train_labels.append(doc.label)\n",
    "        train_features.append(test_model.dv[doc.tags[0]])\n",
    "\n",
    "    \n",
    "    print(\"Length of train_labels list: \", len(train_labels))\n",
    "    print(\"Length of combined paragraph vector: \", len(train_features[1]))\n",
    "    \n",
    "    print(\"Length of individual paragraph vector 1:\", len(test_model.dv[doc.tags[0]]))\n",
    "\n",
    "    return (train_labels, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_labels, train_features = get_training_labels_and_features(model, train_docs_manifests)\n",
    "\n",
    "df_train = {'label': train_labels, 'document_embeddings': train_features}\n",
    "pandas_df_train = pd.DataFrame(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "\n",
    "iso_model = Isomap(n_jobs=10,\n",
    "                  n_components=3,\n",
    "                  max_iter=1000)\n",
    "\n",
    "iso_d2v = iso_model.fit_transform(model.dv.vectors)\n",
    "\n",
    "iso_d2v_df = pd.DataFrame(data=iso_d2v, columns=[\"x\", \"y\", \"z\"])\n",
    "iso_d2v_df[\"label\"] = pandas_df_train[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# [0, 1] = [benign, malicious]\n",
    "colormap = np.array([\"navy\", \"firebrick\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "sequence_containing_x_vals = iso_d2v_df[\"x\"]\n",
    "sequence_containing_y_vals = iso_d2v_df[\"y\"]\n",
    "sequence_containing_z_vals = iso_d2v_df[\"z\"]\n",
    "\n",
    "ax.scatter(sequence_containing_x_vals, \n",
    "           sequence_containing_y_vals, \n",
    "           sequence_containing_z_vals,\n",
    "          c= colormap[iso_d2v_df[\"label\"]])\n",
    "\n",
    "# ax.set_xlim3d(-5, 6)\n",
    "# ax.set_ylim3d(-4, 6)\n",
    "# ax.set_zlim3d(-6, 5)\n",
    "\n",
    "ax.invert_xaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool, BoxSelectTool\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure, show, output_notebook, reset_output\n",
    "from bokeh.palettes import d3\n",
    "import bokeh.models as bmo\n",
    "from bokeh.io import save, output_file\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "plot_d2v = bp.figure(plot_width = 800, plot_height = 700, \n",
    "                       title = \"T-SNE applied to Doc2vec document embeddings\",\n",
    "                       tools = \"pan, wheel_zoom, box_zoom, reset, hover\",\n",
    "                       x_axis_type = None, y_axis_type = None, min_border = 1)\n",
    "\n",
    "source = ColumnDataSource(data = dict(x = iso_d2v_df[\"x\"], \n",
    "                                      y = iso_d2v_df[\"y\"],\n",
    "                                     color = colormap[iso_d2v_df[\"label\"]]))\n",
    "\n",
    "plot_d2v.scatter(x='x', y='y',\n",
    "          color='color',\n",
    "          source=source)\n",
    "\n",
    "\n",
    "show(plot_d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
